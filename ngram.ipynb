{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import statistics\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import string\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_train = []\n",
    "with open(\"../dataset/review_train.json\", \"r\") as file:\n",
    "    for line in file:\n",
    "        review_train.append(json.loads(line))\n",
    "\n",
    "review_test = []\n",
    "with open(\"../dataset/review_test.json\", \"r\") as file:\n",
    "    for line in file:\n",
    "        review_test.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'votes': {'funny': 0, 'useful': 1, 'cool': 0},\n",
       " 'user_id': 'qVlXke5-Qm9Xr0SBcBTTnA',\n",
       " 'review_id': 'K80HPQBnSg7alK7R7tIs3A',\n",
       " 'stars': 1,\n",
       " 'date': '2012-07-02',\n",
       " 'text': 'Terrible place to shop!!! The manager is an expletive i cannot say on here. I went and bought several nails and screws as well as a rug and other items. While i was checking out the cashier charged me incorrectly for some of the screws, actually charged me more than what they were so i told the cashier and she corrected her mistake. While shopping i was there for about an hour because i was looking at paint, i even talked to a guy while i was there about different paint options as well as another lady about drill bits and about my cat condo project. anyway after i left i realize after i got home the cashier had also forgotten to give me a receipt. the rug i purchased did not work where i wanted it so i attempted to return it about 1 week after i purchased it, i went back the following weekend and the manager refused. i have never heard of refusing to return something or even give a store credit. im not one to return stuff so i was completely shocked. when i put up a stink with the manager she absolutely rude. i will never go there and the reason is that this location along with several others are individually owned and because of this they can make up whatever policies they want. so back to Hd or Lowes i go. never again!!',\n",
       " 'type': 'review',\n",
       " 'business_id': '-PisznY2s13FyX3tASY4aA'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_train[0]\n",
    "# len(review_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110355\n",
      "73570\n"
     ]
    }
   ],
   "source": [
    "#spliting data \n",
    "train_data = []\n",
    "N = 110355\n",
    "for d in review_train[:N]:\n",
    "    train_data.append(d)\n",
    "print(len(train_data))\n",
    "valid_data = []\n",
    "for d in review_train[N:]:\n",
    "    valid_data.append(d)\n",
    "print(len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sequence(datum):\n",
    "    seq = []\n",
    "    sp = set(string.punctuation)\n",
    "    # wordCount=defaultdict(int)\n",
    "    r = ''.join([c for c in datum['text'].lower() if not c in sp])\n",
    "    seq = r.split()\n",
    "    return seq \n",
    "    # print(r)\n",
    "    # for w in r.split():\n",
    "    #     wordCountTrain[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183925"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_train = []\n",
    "for d in review_train:\n",
    "    sequences_train.append(process_sequence(d))\n",
    "    # print(process_sequence(d))\n",
    "ratings_train =[]\n",
    "for d in review_train:\n",
    "    ratings_train.append(d['stars'])\n",
    "    # print(d['stars'])\n",
    "len(sequences_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import string\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "\n",
    "class NGramRatingModel:\n",
    "    def __init__(self, n, alpha=1.0):\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "        self.ngrams = defaultdict(list)\n",
    "        self.context_counts = Counter()\n",
    "        self.regressor = Ridge(alpha=self.alpha)\n",
    "\n",
    "    def train(self, sequences, ratings):\n",
    "        for seq, rating in zip(sequences, ratings):\n",
    "            seq = ['<s>'] * (self.n - 1) + seq + ['</s>']\n",
    "            for i in range(len(seq) - self.n + 1):\n",
    "                ngram = tuple(seq[i:i + self.n])\n",
    "                self.ngrams[ngram].append(rating)\n",
    "                self.context_counts[ngram[:-1]] += 1\n",
    "        self.ngrams = {ngram: ratings for ngram, ratings in self.ngrams.items() if len(ratings) > 1}\n",
    "        self.ngram_to_idx = {ngram: idx for idx, ngram in enumerate(self.ngrams.keys())}\n",
    "\n",
    "    def _extract_features_and_targets(self, sequences, ratings):\n",
    "        feature_matrix = lil_matrix((len(sequences), len(self.ngrams)), dtype=np.float32)\n",
    "        for i, seq in enumerate(sequences):\n",
    "            feature_vector = self._extract_features(seq)\n",
    "            feature_matrix[i, :] = feature_vector\n",
    "        return feature_matrix.tocsr(), np.array(ratings, dtype=np.float32)\n",
    "\n",
    "    def _extract_features(self, sequence):\n",
    "        sequence = ['<s>'] * (self.n - 1) + sequence + ['</s>']\n",
    "        feature_vector = np.zeros(len(self.ngrams), dtype=np.float32)\n",
    "        for i in range(len(sequence) - self.n + 1):\n",
    "            ngram = tuple(sequence[i:i + self.n])\n",
    "            if ngram in self.ngram_to_idx:\n",
    "                idx = self.ngram_to_idx[ngram]\n",
    "                feature_vector[idx] += 1\n",
    "        return feature_vector\n",
    "\n",
    "    def evaluate(self, sequences, ratings):\n",
    "        features, targets = self._extract_features_and_targets(sequences, ratings)\n",
    "        predictions = self.regressor.predict(features)\n",
    "        mse = mean_squared_error(targets, predictions)\n",
    "        return mse\n",
    "\n",
    "\n",
    "def process_sequence(datum):\n",
    "    sp = set(string.punctuation)\n",
    "    r = ''.join([c for c in datum['text'].lower() if c not in sp])\n",
    "    return r.split()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(review_train)\n",
    "# Preprocessing\n",
    "train_sequences = [process_sequence(d) for d in review_train[:10000]]\n",
    "train_ratings = [d['stars'] for d in review_train[:10000]]\n",
    "\n",
    "val_sequences = [process_sequence(d) for d in review_train[40000:41999]]\n",
    "val_ratings = [d['stars'] for d in review_train[40000:41999]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 5.4231\n"
     ]
    }
   ],
   "source": [
    "#unigram DON'T WORK TOO WELL\n",
    "\n",
    "# Train and Evaluate\n",
    "ngram_model = NGramRatingModel(n=1, alpha=0.5)\n",
    "ngram_model.train(train_sequences, train_ratings)\n",
    "\n",
    "# Train Ridge Regressor\n",
    "features, targets = ngram_model._extract_features_and_targets(train_sequences, train_ratings)\n",
    "ngram_model.regressor.fit(features, targets)\n",
    "\n",
    "# Validation and Test\n",
    "val_mse = ngram_model.evaluate(val_sequences, val_ratings)\n",
    "\n",
    "print(f\"Validation MSE: {val_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 1.2992\n"
     ]
    }
   ],
   "source": [
    "#bigram\n",
    "# Train and Evaluate\n",
    "ngram_model = NGramRatingModel(n=2, alpha=0.5)\n",
    "ngram_model.train(train_sequences, train_ratings)\n",
    "\n",
    "# Train Ridge Regressor\n",
    "features, targets = ngram_model._extract_features_and_targets(train_sequences, train_ratings)\n",
    "ngram_model.regressor.fit(features, targets)\n",
    "\n",
    "# Validation and Test\n",
    "val_mse = ngram_model.evaluate(val_sequences, val_ratings)\n",
    "\n",
    "print(f\"Validation MSE: {val_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3178\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_sequence = [process_sequence(d) for d in review_test]\n",
    "test_rating = [d['stars'] for d in review_test]\n",
    "\n",
    "test_mse = ngram_model.evaluate(test_sequence,test_rating)\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.490833578439748\n"
     ]
    }
   ],
   "source": [
    "#baseline\n",
    "train_average_stars = sum(d[\"stars\"] for d in review_train) / len(review_train)\n",
    "mse = sum((d[\"stars\"] - train_average_stars) ** 2 for d in review_test) / len(review_test)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
