{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = []\n",
    "with open(\"../dataset/business_all.json\", \"r\") as file:\n",
    "    for line in file:\n",
    "        business.append(json.loads(line))\n",
    "\n",
    "checkin = []\n",
    "with open(\"../dataset/checkin_all.json\", \"r\") as file:\n",
    "    for line in file:\n",
    "        checkin.append(json.loads(line))\n",
    "\n",
    "train_review = []\n",
    "with open(\"../dataset/review_train.json\", \"r\") as file:\n",
    "    for line in file:\n",
    "        train_review.append(json.loads(line))\n",
    "\n",
    "test_review = []\n",
    "with open(\"../dataset/review_test.json\", \"r\") as file:\n",
    "    for line in file:\n",
    "        test_review.append(json.loads(line))\n",
    "\n",
    "users = []\n",
    "with open(\"../dataset/user_all.json\", \"r\") as file:\n",
    "    for line in file:\n",
    "        users.append(json.loads(line))\n",
    "        \n",
    "total_review = train_review + test_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7999973902491008"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_review)/(len(train_review)+len(test_review)) #8:2 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rev, val_rev = train_test_split(train_review, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'votes': {'funny': 0, 'useful': 0, 'cool': 0},\n",
       " 'user_id': 'CcdJ_VhU_zqe2fL7G3eXug',\n",
       " 'review_id': 'aUsn69Kwsnlar7xloj7vCA',\n",
       " 'stars': 4,\n",
       " 'date': '2011-06-02',\n",
       " 'text': \"Postino's has the best brushetta around. Fresh ingredients and a marvelous wine list to go with it. It is always busy but if you go a little early for lunch it is easier to get in.  The parking can be rough but plan ahead and it is worth it.\\nThis is one place with food and atmosphere to rival one of my favorite places in Florence Italy.  Don't rush, be patient and above all be open minded.  You may discover a dish you would have never considered and love it.\",\n",
       " 'type': 'review',\n",
       " 'business_id': 'SDwYQ6eSu1htn8vHWv128g'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_rev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "UserPerRestaurant = defaultdict(list)\n",
    "RestaurantPerUser = defaultdict(list)\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "for review in train_rev:\n",
    "    u = review['user_id']\n",
    "    restaurant = review['business_id']\n",
    "    rate = review['stars'] \n",
    "    \n",
    "    UserPerRestaurant[restaurant].append(u)\n",
    "    RestaurantPerUser[u].append(restaurant)\n",
    "    \n",
    "    ratingsPerUser[u].append((restaurant,rate))\n",
    "    ratingsPerItem[restaurant].append((u,rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurantCount = defaultdict(int)\n",
    "totalEat = 0\n",
    "\n",
    "for review in total_review:\n",
    "    u = review['user_id']\n",
    "    restaurant = review['business_id']\n",
    "    rate = review['stars'] \n",
    "    restaurantCount[restaurant] +=1\n",
    "    totalEat+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train null/empty reviews: 4\n",
      "Number of val null/empty reviews: 1\n",
      "Number of test null/empty reviews: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['0g3vPgL4oW7sBxZA6R2ZXQ',\n",
       "  'NOhzie7YJMprviyeaEh_AQ',\n",
       "  'K7fQAOToFP_pXiE7f5OLUg',\n",
       "  'bY6XggJUzpO6SNUOaS3zaw'],\n",
       " ['w8LVmdgVqdSYsuPR0RoZZA'],\n",
       " ['PY-Eir6BUMMfw1u0_OipiA'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_train_reviews_id = [\n",
    "    review[\"review_id\"] for review in train_rev \n",
    "    if review['text'] is None or review['text'].strip() == ''\n",
    "]\n",
    "print(f\"Number of train null/empty reviews: {len(null_train_reviews_id)}\")\n",
    "\n",
    "null_val_reviews_id = [\n",
    "    review[\"review_id\"] for review in val_rev \n",
    "    if review['text'] is None or review['text'].strip() == ''\n",
    "]\n",
    "print(f\"Number of val null/empty reviews: {len(null_val_reviews_id)}\")\n",
    "\n",
    "null_test_reviews_id = [\n",
    "    review[\"review_id\"] for review in test_review \n",
    "    if review['text'] is None or review['text'].strip() == ''\n",
    "]\n",
    "print(f\"Number of test null/empty reviews: {len(null_test_reviews_id)}\")\n",
    "\n",
    "null_train_reviews_id,null_val_reviews_id,null_test_reviews_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_dict = {user['user_id']: user for user in users}\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "total_length = 0\n",
    "for review in train_rev:\n",
    "    if review[\"review_id\"] == null_train_reviews_id: continue\n",
    "    total_length += sum(1 for char in review['text'] if char.isalnum())\n",
    "avg_review_length = total_length / (len(train_rev) - len(null_train_reviews_id)) if train_rev else 0\n",
    "\n",
    "for review in train_rev:\n",
    "    if review[\"review_id\"] == null_train_reviews_id: continue\n",
    "    user_id = review['user_id']\n",
    "    restaurant = review['business_id']\n",
    "    rate = review['stars']\n",
    "    #1\n",
    "    user_data = users_dict.get(user_id)\n",
    "    if user_data:\n",
    "        review_count = user_data['review_count']\n",
    "        if review_count < 50:\n",
    "            avg_rating_category = 'Low'\n",
    "        elif review_count < 100:\n",
    "            avg_rating_category = 'Medium'\n",
    "        else:\n",
    "            avg_rating_category = 'High'\n",
    "        avg_rating_category_numeric = {'Low': 0, 'Medium': 1, 'High': 2}[avg_rating_category]\n",
    "#2\n",
    "    avg_user_rating = np.mean([rate for _, rate in ratingsPerUser[user_id]]) if ratingsPerUser[user_id] else 0\n",
    "    avg_restaurant_rating = np.mean([rate for _, rate in ratingsPerItem[restaurant]]) if ratingsPerItem[restaurant] else 0\n",
    "\n",
    "    avg_review_length = sum(1 for char in review['text'] if char.isalnum())\n",
    "\n",
    "    features = np.array([ avg_review_length, avg_restaurant_rating,avg_rating_category_numeric ])\n",
    "    X_train.append(features)\n",
    "    y_train.append(rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_dict = {user['user_id']: user for user in users}\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "total_length = 0\n",
    "for review in val_rev:\n",
    "    if review[\"review_id\"] == null_val_reviews_id: continue\n",
    "    total_length += sum(1 for char in review['text'] if char.isalnum())\n",
    "avg_review_length = total_length / (len(val_rev) - len(null_val_reviews_id)) if val_rev else 0\n",
    "\n",
    "for val_review in val_rev:\n",
    "    if val_review[\"review_id\"] == null_val_reviews_id: continue\n",
    "    val_user_id = val_review['user_id']\n",
    "    val_restaurant = val_review['business_id']\n",
    "    val_rate = val_review['stars']\n",
    "\n",
    "    user_data = users_dict.get(val_user_id)\n",
    "    if user_data:\n",
    "        review_count = user_data['review_count']\n",
    "\n",
    "        if review_count < 50:\n",
    "            avg_rating_category = 'Low'\n",
    "        elif review_count < 100:\n",
    "            avg_rating_category = 'Medium'\n",
    "        else:\n",
    "            avg_rating_category = 'High'\n",
    "        \n",
    "        avg_rating_category_numeric = {'Low': 0, 'Medium': 1, 'High': 2}[avg_rating_category]\n",
    "        avg_user_rating = np.mean([rate for _, rate in ratingsPerUser[val_user_id]]) if ratingsPerUser[val_user_id] else 0\n",
    "        avg_restaurant_rating = np.mean([rate for _, rate in ratingsPerItem[val_restaurant]]) if ratingsPerItem[val_restaurant] else 0\n",
    "\n",
    "        avg_review_length = sum(1 for char in val_review['text'] if char.isalnum())\n",
    "    \n",
    "        val_features = np.array([avg_review_length, avg_restaurant_rating, avg_rating_category_numeric])\n",
    "        X_val.append(val_features)\n",
    "        y_val.append(val_rate)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3r/0t8vw1nd17s_qplm7_7lyjl00000gn/T/ipykernel_1890/2365385329.py:1: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  theta, residuals, rank, s = np.linalg.lstsq(X_train, y_train)\n"
     ]
    }
   ],
   "source": [
    "theta, residuals, rank, s = np.linalg.lstsq(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.79453557e-04,  1.03603500e+00,  1.66433132e-02])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.matmul(X_val, theta)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]  <1:\n",
    "        y_pred[i] = 1\n",
    "    if y_pred[i] > 5:\n",
    "        y_pred[i] = 5\n",
    "        \n",
    "mse = np.mean((y_val-y_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation MSE:  1.3904127025277067\n"
     ]
    }
   ],
   "source": [
    "print(\"validation MSE: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "total_length = 0\n",
    "for review in test_review:\n",
    "    if review[\"review_id\"] == null_test_reviews_id: continue\n",
    "    total_length += sum(1 for char in review['text'] if char.isalnum())\n",
    "avg_review_length = total_length / (len(test_review) - len(null_test_reviews_id)) if test_review else 0\n",
    "\n",
    "for review in test_review:\n",
    "    if review[\"review_id\"] == null_test_reviews_id: continue\n",
    "    test_user_id = review['user_id']\n",
    "    test_restaurant = review['business_id']\n",
    "    test_rate = review['stars']\n",
    "\n",
    "    user_data = users_dict.get(test_user_id)\n",
    "    if user_data:\n",
    "        review_count = user_data['review_count']\n",
    "\n",
    "        if review_count < 50:\n",
    "            avg_rating_category = 'Low'\n",
    "        elif review_count < 100:\n",
    "            avg_rating_category = 'Medium'\n",
    "        else:\n",
    "            avg_rating_category = 'High'\n",
    "        \n",
    "        avg_rating_category_numeric = {'Low': 0, 'Medium': 1, 'High': 2}[avg_rating_category]\n",
    "        avg_user_rating = np.mean([rate for _, rate in ratingsPerUser[test_user_id]]) if ratingsPerUser[test_user_id] else 0\n",
    "        avg_restaurant_rating = np.mean([rate for _, rate in ratingsPerItem[test_restaurant]]) if ratingsPerItem[test_restaurant] else 0\n",
    "\n",
    "        avg_review_length = sum(1 for char in review['text'] if char.isalnum())\n",
    "    \n",
    "        test_features = np.array([avg_review_length, avg_restaurant_rating, avg_rating_category_numeric])\n",
    "        X_test.append(test_features)\n",
    "        y_test.append(test_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MSE:  1.3933411621857406\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.matmul(X_test, theta)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]  <1:\n",
    "        y_pred[i] = 1\n",
    "    if y_pred[i] > 5:\n",
    "        y_pred[i] = 5\n",
    "        \n",
    "mse = np.mean((y_test-y_pred)**2)\n",
    "print(\"test MSE: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
