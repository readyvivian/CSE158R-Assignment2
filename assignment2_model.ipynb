{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = []\n",
    "with open(\"../dataset/business_all.json\", \"r\") as file:\n",
    "    for line in file:\n",
    "        business.append(json.loads(line))\n",
    "\n",
    "checkin = []\n",
    "with open(\"../dataset/checkin_all.json\", \"r\") as file:\n",
    "    for line in file:\n",
    "        checkin.append(json.loads(line))\n",
    "\n",
    "train_review = []\n",
    "with open(\"../dataset/review_train.json\", \"r\") as file:\n",
    "    for line in file:\n",
    "        train_review.append(json.loads(line))\n",
    "\n",
    "test_review = []\n",
    "with open(\"../dataset/review_test.json\", \"r\") as file:\n",
    "    for line in file:\n",
    "        test_review.append(json.loads(line))\n",
    "\n",
    "user = []\n",
    "with open(\"../dataset/user_all.json\", \"r\") as file:\n",
    "    for line in file:\n",
    "        user.append(json.loads(line))\n",
    "        \n",
    "total_review = train_review + test_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7999973902491008"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_review)/(len(train_review)+len(test_review)) #8:2 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rev, val_rev = train_test_split(train_review, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'votes': {'funny': 0, 'useful': 0, 'cool': 0},\n",
       " 'user_id': 'CcdJ_VhU_zqe2fL7G3eXug',\n",
       " 'review_id': 'aUsn69Kwsnlar7xloj7vCA',\n",
       " 'stars': 4,\n",
       " 'date': '2011-06-02',\n",
       " 'text': \"Postino's has the best brushetta around. Fresh ingredients and a marvelous wine list to go with it. It is always busy but if you go a little early for lunch it is easier to get in.  The parking can be rough but plan ahead and it is worth it.\\nThis is one place with food and atmosphere to rival one of my favorite places in Florence Italy.  Don't rush, be patient and above all be open minded.  You may discover a dish you would have never considered and love it.\",\n",
       " 'type': 'review',\n",
       " 'business_id': 'SDwYQ6eSu1htn8vHWv128g'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_rev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "UserPerRestaurant = defaultdict(list)\n",
    "RestaurantPerUser = defaultdict(list)\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "for review in train_rev:\n",
    "    user = review['user_id']\n",
    "    restaurant = review['business_id']\n",
    "    rate = review['stars'] \n",
    "    \n",
    "    UserPerRestaurant[restaurant].append(user)\n",
    "    RestaurantPerUser[user].append(restaurant)\n",
    "    \n",
    "    ratingsPerUser[user].append((restaurant,rate))\n",
    "    ratingsPerItem[restaurant].append((user,rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurantCount = defaultdict(int)\n",
    "totalEat = 0\n",
    "\n",
    "for review in total_review:\n",
    "    user = review['user_id']\n",
    "    restaurant = review['business_id']\n",
    "    rate = review['stars'] \n",
    "    restaurantCount[restaurant] +=1\n",
    "    totalEat+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for review in train_rev:\n",
    "    user = review['user_id']\n",
    "    restaurant = review['business_id']\n",
    "    rate = review['stars']  # This is the rating (1, 2, 3, 4, or 5)\n",
    "    \n",
    "    # Extract features (normalized popularity, review counts, average ratings, etc.)\n",
    "    popularity_score = restaurantCount[restaurant] / totalEat if restaurant in restaurantCount else 0\n",
    "    user_review_count = len(RestaurantPerUser[user])\n",
    "    avg_user_rating = np.mean([rate for _, rate in ratingsPerUser[user]]) if ratingsPerUser[user] else 0\n",
    "    restaurant_review_count = len(UserPerRestaurant[restaurant])\n",
    "    avg_restaurant_rating = np.mean([rate for _, rate in ratingsPerItem[restaurant]]) if ratingsPerItem[restaurant] else 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    #features = np.array([popularity_score, user_review_count, avg_user_rating, restaurant_review_count, avg_restaurant_rating])\n",
    "    features = np.array([avg_restaurant_rating,restaurant_review_count,popularity_score])\n",
    "    X_train.append(features)\n",
    "    y_train.append(rate)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "for val_review in val_rev:\n",
    "    val_user = val_review['user_id']\n",
    "    val_restaurant = val_review['business_id']\n",
    "    val_rate = val_review['stars']  \n",
    "\n",
    "    # Feature 1: normalized Popularity\n",
    "    popularity_score = restaurantCount[val_restaurant] / totalEat if val_restaurant in restaurantCount else 0\n",
    "\n",
    "    # Feature 2: User Review Count (how many reviews the user has written)\n",
    "    user_review_count = len(RestaurantPerUser[val_user])\n",
    "\n",
    "    # Feature 3: Average User Rating (average rating given by this user)\n",
    "    avg_user_rating = np.mean([rate for _, rate in ratingsPerUser[val_user]]) if ratingsPerUser[val_user] else 0\n",
    "\n",
    "    # Feature 4: Restaurant Review Count (how many reviews this restaurant has)\n",
    "    restaurant_review_count = len(UserPerRestaurant[val_restaurant])\n",
    "\n",
    "    # Feature 5: Restaurant Average Rating (average rating for this restaurant)\n",
    "    avg_restaurant_rating = np.mean([rate for _, rate in ratingsPerItem[val_restaurant]]) if ratingsPerItem[val_restaurant] else 0\n",
    "    \n",
    "   # val_features = np.array([popularity_score, user_review_count, avg_user_rating, restaurant_review_count, avg_restaurant_rating])\n",
    "    val_features = np.array([avg_restaurant_rating,restaurant_review_count,popularity_score])\n",
    "    X_val.append(val_features)\n",
    "    y_val.append(val_rate)\n",
    "\n",
    "\n",
    "\n",
    "# total_pred = 0\n",
    "# correct_pred = 0\n",
    "# for true, pred in zip(y_val, predicted_classes):\n",
    "#     if true == pred:\n",
    "#         correct_pred +=1\n",
    "#     total_pred += 1\n",
    "\n",
    "# accuracy = correct_pred/float(total_pred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.60714286e+00, 2.80000000e+01, 1.65284224e-04])"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3r/0t8vw1nd17s_qplm7_7lyjl00000gn/T/ipykernel_77670/1373657082.py:1: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  theta, residuals, rank, s = np.linalg.lstsq(X_train, y_train)\n"
     ]
    }
   ],
   "source": [
    "theta, residuals, rank, s = np.linalg.lstsq(X_train, y_train)\n",
    "\n",
    "# Unpack the result\n",
    "#theta0, theta1, theta2= theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.matmul(X_val, theta)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]  <1:\n",
    "        y_pred[i] = 1\n",
    "    if y_pred[i] > 5:\n",
    "        y_pred[i] = 5\n",
    "        \n",
    "mse = np.mean((y_val-y_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4064451825596227"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.50546448, 4.2       , 3.96969697, ..., 3.83333333, 3.73195876,\n",
       "       3.52272727])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
